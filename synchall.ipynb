{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install azure-storage-blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from io import StringIO\n",
    "\n",
    "# Step 1: Perform a full search to get all documents in the index\n",
    "def search_index(base_url, index_name, api_key):\n",
    "    \"\"\"\n",
    "    Queries an Azure Cognitive Search index to retrieve all documents.\n",
    "    \n",
    "    Args:\n",
    "        base_url (str): The base URL of the Azure Cognitive Search service.\n",
    "        index_name (str): The name of the search index.\n",
    "        api_key (str): The API key for authenticating requests to the search service.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are `id` and the values are `content` for each document.\n",
    "        Returns an empty dictionary if there is an error.\n",
    "    \"\"\"\n",
    "    search_url = f\"{base_url}/indexes/{index_name}/docs/search?api-version=2024-07-01\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "    query = {\n",
    "        \"search\": \"*\",\n",
    "        \"select\": \"id, content\"\n",
    "    }\n",
    "    \n",
    "    # Make the search request\n",
    "    response = requests.post(search_url, headers=headers, json=query)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Parse and return search results\n",
    "        search_results = response.json()\n",
    "        return {doc[\"id\"]: doc[\"content\"] for doc in search_results[\"value\"]}\n",
    "    else:\n",
    "        # Handle any errors\n",
    "        print(f\"Error during search: {response.status_code}, {response.text}\")\n",
    "        return {}\n",
    "\n",
    "# Step 2: Load CSV file from Azure Blob Storage\n",
    "def load_csv_from_blob(connection_string, container_name, blob_name):\n",
    "    \"\"\"\n",
    "    Downloads and reads a CSV file from Azure Blob Storage, and converts it to a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        connection_string (str): Connection string to the Azure Blob Storage account.\n",
    "        container_name (str): The name of the Blob Storage container.\n",
    "        blob_name (str): The name of the CSV file in the container.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are `id` and the values are `content` for each record in the CSV.\n",
    "    \"\"\"\n",
    "    # Create BlobServiceClient using the connection string\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    \n",
    "    # Download the blob's content as a string\n",
    "    download_stream = blob_client.download_blob()\n",
    "    csv_data = download_stream.readall().decode(\"utf-8\")\n",
    "    \n",
    "    # Load CSV into pandas DataFrame from the string content\n",
    "    df = pd.read_csv(StringIO(csv_data))\n",
    "    \n",
    "    # Convert CSV into a dictionary with `id` as key\n",
    "    return {f'{row[\"id\"]}': row[\"content\"] for _, row in df.iterrows()}\n",
    "\n",
    "# Step 3: Delete records from the index that are not in the CSV\n",
    "def delete_documents_from_index(base_url, index_name, api_key, doc_ids_to_delete, index_data):\n",
    "    \"\"\"\n",
    "    Deletes documents from the Azure Cognitive Search index based on provided `id`s.\n",
    "    \n",
    "    Args:\n",
    "        base_url (str): The base URL of the Azure Cognitive Search service.\n",
    "        index_name (str): The name of the search index.\n",
    "        api_key (str): The API key for authenticating requests to the search service.\n",
    "        doc_ids_to_delete (list): A list of `id`s that need to be deleted from the index.\n",
    "        index_data (dict): Current data in the index, with `id` as key and `content` as value.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    delete_url = f\"{base_url}/indexes/{index_name}/docs/index?api-version=2024-07-01\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "    \n",
    "    # Log the documents to be deleted\n",
    "    print(\"Deleting the following documents:\")\n",
    "    for doc_id in doc_ids_to_delete:\n",
    "        content = index_data.get(doc_id, \"Content not available\")\n",
    "        print(f\"ID: {doc_id}, {content[:30]}...\")\n",
    "    \n",
    "    # Prepare the data for deletion\n",
    "    delete_data = {\n",
    "        \"value\": [{\"@search.action\": \"delete\", \"id\": doc_id} for doc_id in doc_ids_to_delete]\n",
    "    }\n",
    "\n",
    "    # Send the delete request to Azure Cognitive Search\n",
    "    response = requests.post(delete_url, headers=headers, json=delete_data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Successfully deleted {len(doc_ids_to_delete)} documents.\")\n",
    "    else:\n",
    "        print(f\"Error during deletion: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "base_url = os.getenv(\"SEARCH_SERVICE_URL\")\n",
    "index_name = os.getenv(\"INDEX_NAME\")\n",
    "api_key = os.getenv(\"SEARCH_API_KEY\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all records from the index\n",
    "index_data = search_index(base_url, index_name, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: Gastronomic Landscape Hotel -1\n",
      "4: Sublime Palace Hotel\n",
      "2: Old Century Hotel -1\n",
      "1: Stay-Kay City Hotel -1\n"
     ]
    }
   ],
   "source": [
    "for key, value in index_data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "blob_name = os.getenv(\"AZURE_STORAGE_BLOB_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data from Azure Blob Storage\n",
    "csv_data = load_csv_from_blob(connection_string, container_name, blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Stay-Kay City Hotel -1\n",
      "2: Old Century Hotel -1\n",
      "3: Gastronomic Landscape Hotel -1\n"
     ]
    }
   ],
   "source": [
    "for key, value in csv_data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '4', '2', '1']\n",
      "['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "print(list(index_data.keys()))\n",
    "print(list(csv_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing IDs: ['4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find records in the CSV that are not in the index\n",
    "missing_ids = [doc_id for doc_id in index_data if doc_id not in csv_data]\n",
    "\n",
    "\n",
    "print(f\"Missing IDs: {missing_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the following documents:\n",
      "ID: 4, Sublime Palace Hotel...\n",
      "Successfully deleted 1 documents.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If there are missing records, delete them from the index\n",
    "if missing_ids:\n",
    "    delete_documents_from_index(base_url, index_name, api_key, missing_ids, index_data)\n",
    "else:\n",
    "    print(\"No documents to delete. All records in the CSV are present in the index.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
